{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/statzenthusiast921/Personal-Projects/blob/main/Office_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8JCGlV1YkVs"
      },
      "outputs": [],
      "source": [
        "#Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#!pip install keras\n",
        "from tensorflow import keras \n",
        "import random\n",
        "import sqlite3\n",
        "from keras.models import Sequential\n",
        "\n",
        "from tensorflow.keras.layers import Input, Dropout, Dense, concatenate, Embedding\n",
        "from tensorflow.keras.layers import Flatten, Activation\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "#!pip install np_utils\n",
        "#!conda install keras -y\n",
        "# from tensorflow.keras.utils import np_utils\n",
        "# from keras.utils.np_utils import to_categorical\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "#from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.compat.v1.keras.layers import CuDNNGRU, CuDNNLSTM\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import MaxPooling1D\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fTdQbZaCY_xp",
        "outputId": "f9de9eff-d1fd-47cb-a776-8e5dd5baa185"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import os\n",
        "os.getcwd()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "V3E48LhwbK8N",
        "outputId": "a611fd5e-81fa-4099-af8d-154744f64934"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5e8f8011-c888-4fcd-a1ca-678a7c1ff4dd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5e8f8011-c888-4fcd-a1ca-678a7c1ff4dd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving the-office-lines.xlsx to the-office-lines.xlsx\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4hUNl80ZvC5",
        "outputId": "93021b38-55ca-4294-8737-947bbb16939b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OP_yw7pmZ9VV",
        "outputId": "bc41e9ce-d967-4b4d-ed84-3933c74d3973"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/My\\ Drive/\n",
        "\n",
        "#%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "S9R2CcbTYnm6",
        "outputId": "52e4a963-1796-423e-af9f-9fee2c44a1c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>speaker</th>\n",
              "      <th>line_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Michael</td>\n",
              "      <td>All right Jim. Your quarterlies look very good...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Jim</td>\n",
              "      <td>Oh, I told you. I couldn't close it. So...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Michael</td>\n",
              "      <td>So you've come to the master for guidance? Is ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Jim</td>\n",
              "      <td>Actually, you called me in here, but yeah.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Michael</td>\n",
              "      <td>All right. Well, let me show you how it's done.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Michael</td>\n",
              "      <td>[on the phone] Yes, I'd like to speak to your ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Michael</td>\n",
              "      <td>I've, uh, I've been at Dunder Mifflin for 12 y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Pam</td>\n",
              "      <td>Well. I don't know.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Michael</td>\n",
              "      <td>If you think she's cute now, you should have s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Pam</td>\n",
              "      <td>What?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   speaker                                          line_text\n",
              "0  Michael  All right Jim. Your quarterlies look very good...\n",
              "1      Jim         Oh, I told you. I couldn't close it. So...\n",
              "2  Michael  So you've come to the master for guidance? Is ...\n",
              "3      Jim         Actually, you called me in here, but yeah.\n",
              "4  Michael    All right. Well, let me show you how it's done.\n",
              "5  Michael  [on the phone] Yes, I'd like to speak to your ...\n",
              "6  Michael  I've, uh, I've been at Dunder Mifflin for 12 y...\n",
              "7      Pam                                Well. I don't know.\n",
              "8  Michael  If you think she's cute now, you should have s...\n",
              "9      Pam                                              What?"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "#Changing database into text\n",
        "df = pd.read_excel('/content/the-office-lines.xlsx')\n",
        "\n",
        "\n",
        "df.speaker = df.speaker.astype(str)\n",
        "df.line_text = df.line_text.astype(str)\n",
        "df = df[[\"speaker\",\"line_text\"]]\n",
        "\n",
        "df[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GBjdJ8haQbI",
        "outputId": "bb47bcc7-e89c-467e-e0d8-6e0d7cbb55b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "michael: all right jim. your quarterlies look very good. how are things at the library? \n",
            "\n",
            "jim: oh, i told you. i couldn't close it. so... \n",
            "\n",
            "michael: so you've come to the master for guidance? is this what you're saying, grasshopper? \n",
            "\n",
            "jim: actually, you called me in here, but yeah. \n",
            "\n",
            "michael: all right. well, let me show you how it's done. \n",
            "\n",
            "michael: [on the phone] yes, i'd like to speak to your office manager, please. yes, hello. this is michael scott. i am the regional manager of dunder mifflin paper products. just wanted to talk to you manager-a-manger. [quick cut scene] all right. done deal. thank you very much, sir. you're a gentleman and a scholar. oh, i'm sorry. ok. i'm sorry. my mistake. [hangs up] that was a woman i was talking to, so... she had a very low voice. probably a smoker, so... [clears throat] so that's the way it's done. \n",
            "\n",
            "michael: i've, uh, i've been at dunder mifflin for 12 years, the last four as regional manager. if you want to come through here... see we have the entire floor. so this is my kingdom, as far as the eye can see. this is our receptionist, pam. pam! pam-pam! pam beesly. pam has been with us for...  forever. right, pam? \n",
            "\n",
            "pam: well. i don't know. \n",
            "\n",
            "michael: if you think she's cute now, you should have seen her a couple of years ago. [growls] \n",
            "\n",
            "pam: what? \n",
            "\n",
            "michael: any messages? \n",
            "\n",
            "pam: uh, yeah. just a fax. \n",
            "\n",
            "michael: oh! pam, this is from corporate. how many times have i told you? there's a special filing cabinet for things from corporate. \n",
            "\n",
            "pam: you haven't told me. \n",
            "\n",
            "michael: it's called the wastepaper basket! look at that! look at that face. \n",
            "\n",
            "michael: people say i am the best boss. they go, 'god we've never worked in a place like this before. you're hilarious.' 'and you get the best out of us.' [shows the camera his world's best boss mug] i think that pretty much sums it up. i found it at spencer gifts. \n",
            "\n",
            "dwight: [singing] shall i play for you? pa rum pump um pum [imitates heavy drumming] i have no gifts for you. pa rum pump \n",
            "CPU times: user 80.4 ms, sys: 6.98 ms, total: 87.4 ms\n",
            "Wall time: 88.6 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "All_Office_Scripts = ''\n",
        "last_seg = ''\n",
        "\n",
        "for line in df.values:\n",
        "#     print(line[0])\n",
        "#     print(line[2])\n",
        "    character = line[0].lower()\n",
        "    dialogue = line[1].lower()\n",
        "    script = character+\": \"+dialogue+\" \\n\\n\"\n",
        "    All_Office_Scripts += script\n",
        "\n",
        "print(All_Office_Scripts[:2000])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1U_0HzWGYqcf"
      },
      "outputs": [],
      "source": [
        "text_file = open(\"All_Office_Scripts.txt\", \"w\")\n",
        "text_file.write(All_Office_Scripts)\n",
        "text_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiCrpIb9yRSr",
        "outputId": "f89b7d69-f4e3-4728-d125-db0b222f8fbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\n', ' ', '!', '#', '$', '%', '&', \"'\", '(', ')', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ]
        }
      ],
      "source": [
        "#Prep text for RNN\n",
        "Text_Data = All_Office_Scripts.lower()\n",
        "\n",
        "if len(Text_Data) > 500000:\n",
        "    Text_Data = Text_Data[:500000]\n",
        "\n",
        "charindex = list(set(Text_Data))\n",
        "charindex.sort() \n",
        "print(charindex)\n",
        "\n",
        "np.save(\"charindex.npy\", charindex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csWg9G40yTsk",
        "outputId": "1bc5c4e1-c996-4ad4-e29f-55ef4fb8bd08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 30.6 s, sys: 448 ms, total: 31 s\n",
            "Wall time: 31 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "CHARS_SIZE = len(charindex)\n",
        "SEQUENCE_LENGTH = 75\n",
        "X_train = []\n",
        "Y_train = []\n",
        "for i in range(0, len(Text_Data)-SEQUENCE_LENGTH, 1 ): \n",
        "    X = Text_Data[i:i + SEQUENCE_LENGTH]\n",
        "    Y = Text_Data[i + SEQUENCE_LENGTH]\n",
        "    X_train.append([charindex.index(x) for x in X])\n",
        "    Y_train.append(charindex.index(Y))\n",
        "\n",
        "X_train = np.reshape(X_train, (len(X_train), SEQUENCE_LENGTH))\n",
        "\n",
        "Y_train = keras.utils.to_categorical(Y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTschx-ayWgZ",
        "outputId": "927995b9-7945-42bf-caef-6d823b25801d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 75)]              0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 75, 75)            4125      \n",
            "                                                                 \n",
            " cu_dnnlstm (CuDNNLSTM)      (None, 75, 512)           1206272   \n",
            "                                                                 \n",
            " cu_dnnlstm_1 (CuDNNLSTM)    (None, 75, 512)           2101248   \n",
            "                                                                 \n",
            " cu_dnnlstm_2 (CuDNNLSTM)    (None, 512)               2101248   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 55)                7095      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,584,212\n",
            "Trainable params: 5,580,087\n",
            "Non-trainable params: 4,125\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#!pip install -U numpy==1.18.5\n",
        "#!conda install python=3.6\n",
        "#Create the model\n",
        "\n",
        "\n",
        "def get_model():\n",
        "    model = Sequential()\n",
        "    inp = Input(shape=(SEQUENCE_LENGTH, ))\n",
        "    x = Embedding(CHARS_SIZE, 75, trainable=False)(inp)\n",
        "    x = CuDNNLSTM(512, return_sequences=True,)(x)\n",
        "    x = CuDNNLSTM(512, return_sequences=True,)(x)\n",
        "    x = CuDNNLSTM(512,)(x)\n",
        "    x = Dense(256, activation=\"elu\")(x)\n",
        "    x = Dense(128, activation=\"elu\")(x)\n",
        "    outp = Dense(CHARS_SIZE, activation='softmax')(x)\n",
        "    \n",
        "    model = Model(inputs=inp, outputs=outp)\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=Adam(lr=0.001),\n",
        "                  metrics=['accuracy'],\n",
        "                 )\n",
        "\n",
        "    return model\n",
        "\n",
        "model = get_model()\n",
        "\n",
        "model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxJXWGIuyg61"
      },
      "outputs": [],
      "source": [
        "#Checkpoints and Custom Callback\n",
        "filepath=\"model_checkpoint.hdf5\"\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath,\n",
        "                             monitor='loss',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True,\n",
        "                             mode='min')\n",
        "\n",
        "early = EarlyStopping(monitor=\"loss\",\n",
        "                      mode=\"min\",\n",
        "                      patience=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctW3HlhNyk1x"
      },
      "outputs": [],
      "source": [
        "class TextSample(Callback):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Callback, self).__init__() \n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        pattern = X_train[700]\n",
        "        outp = []\n",
        "        seed = [charindex[x] for x in pattern]\n",
        "        sample = 'TextSample:' +''.join(seed)+'|'\n",
        "        for t in range(100):\n",
        "            x = np.reshape(pattern, (1, len(pattern)))\n",
        "            pred = self.model.predict(x)\n",
        "            result = np.argmax(pred)\n",
        "            outp.append(result)\n",
        "            pattern = np.append(pattern,result)\n",
        "            pattern = pattern[1:len(pattern)]\n",
        "        outp = [charindex[x] for x in outp]\n",
        "        outp = ''.join(outp)\n",
        "        sample += outp\n",
        "        print(sample)\n",
        "\n",
        "textsample = TextSample()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3jIXTt9ytRH"
      },
      "outputs": [],
      "source": [
        "#!pwd\n",
        "#%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fS6qUiWXymdx"
      },
      "outputs": [],
      "source": [
        "#Load model\n",
        "#filepath='/content/drive/My Drive/model_checkpoint.hdf5'\n",
        "# model = load_model(filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TN5PO4YIyqwc",
        "outputId": "74202059-acf3-420b-c0e1-8684839b6b46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "   6/1953 [..............................] - ETA: 13:19 - loss: 3.9993 - accuracy: 0.1146WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1412s vs `on_train_batch_end` time: 0.2659s). Check your callbacks.\n",
            "1953/1953 [==============================] - ETA: 0s - loss: 2.0150 - accuracy: 0.4300\n",
            "Epoch 00001: loss improved from inf to 2.01502, saving model to model_checkpoint.hdf5\n",
            "TextSample:ake. [hangs up] that was a woman i was talking to, so... she had a very low| and the best of the because that is a back of the because that is a back of the because that is a b\n",
            "1953/1953 [==============================] - 807s 410ms/step - loss: 2.0150 - accuracy: 0.4300\n",
            "Epoch 2/5\n",
            "1953/1953 [==============================] - ETA: 0s - loss: 1.3280 - accuracy: 0.5981\n",
            "Epoch 00002: loss improved from 2.01502 to 1.32804, saving model to model_checkpoint.hdf5\n",
            "TextSample:ake. [hangs up] that was a woman i was talking to, so... she had a very low|er to start to the best of the best of the best of the best of the best of the best of the best of t\n",
            "1953/1953 [==============================] - 792s 406ms/step - loss: 1.3280 - accuracy: 0.5981\n",
            "Epoch 3/5\n",
            "1953/1953 [==============================] - ETA: 0s - loss: 1.1939 - accuracy: 0.6322\n",
            "Epoch 00003: loss improved from 1.32804 to 1.19390, saving model to model_checkpoint.hdf5\n",
            "TextSample:ake. [hangs up] that was a woman i was talking to, so... she had a very low|ing a little for the party for the party for the party for the party for the party for the party for\n",
            "1953/1953 [==============================] - 798s 409ms/step - loss: 1.1939 - accuracy: 0.6322\n",
            "Epoch 4/5\n",
            "1953/1953 [==============================] - ETA: 0s - loss: 1.1106 - accuracy: 0.6545\n",
            "Epoch 00004: loss improved from 1.19390 to 1.11064, saving model to model_checkpoint.hdf5\n",
            "TextSample:ake. [hangs up] that was a woman i was talking to, so... she had a very low|er. \n",
            "\n",
            "dwight: i don't know what you should be the bottle of the bottle of the bottle of the bottle o\n",
            "1953/1953 [==============================] - 801s 410ms/step - loss: 1.1106 - accuracy: 0.6545\n",
            "Epoch 5/5\n",
            "1953/1953 [==============================] - ETA: 0s - loss: 1.0426 - accuracy: 0.6729\n",
            "Epoch 00005: loss improved from 1.11064 to 1.04265, saving model to model_checkpoint.hdf5\n",
            "TextSample:ake. [hangs up] that was a woman i was talking to, so... she had a very low|er. \n",
            "\n",
            "dwight: i want to talk to you and then i was a good guy and going to be a good time. \n",
            "\n",
            "michael\n",
            "1953/1953 [==============================] - 800s 409ms/step - loss: 1.0426 - accuracy: 0.6729\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f447288ae10>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "#Train the model\n",
        "model_callbacks = [checkpoint, early, textsample]\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=256,\n",
        "          epochs=5,\n",
        "          verbose=1,\n",
        "          callbacks = model_callbacks)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zC1lKadtzIRj"
      },
      "outputs": [],
      "source": [
        "#Save the model\n",
        "# model = load_model(filepath)\n",
        "model.save_weights(\"full_train_weights.hdf5\")\n",
        "model.save(\"full_train_model.hdf5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCpRsylHSbL_",
        "outputId": "d09ca672-b779-4462-fad2-9466bfdb9eac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "%0.0 done\n",
            "%10.0 done\n",
            "%20.0 done\n",
            "%30.0 done\n",
            "%40.0 done\n",
            "%50.0 done\n",
            "%60.0 done\n",
            "%70.0 done\n",
            "%80.0 done\n",
            "%90.0 done\n",
            ": i want to go to the time. \n",
            "\n",
            "dwight: i want to talk to you and then i was a good guy and good to the boat. \n",
            "\n",
            "michael: i want to go to the time. \n",
            "\n",
            "dwight: i want to talk to you and then i want to go to the time. \n",
            "\n",
            "michael: i want to go to the time. \n",
            "\n",
            "dwight: i want to talk to you and then i was a good guy and going to be a good time. \n",
            "\n",
            "michael: i want to go to the time. \n",
            "\n",
            "dwight: i want to talk to you and then i want to say that i was a good guy and good to the best dundie. \n",
            "\n",
            "michael: i want to go to the time. \n",
            "\n",
            "michael: i want to go to the time. \n",
            "\n",
            "dwight: i want to talk to you and then i was a good guy and going to get the fire guy. \n",
            "\n",
            "michael: i want to take the same time. \n",
            "\n",
            "michael: i want to go to the time. \n",
            "\n",
            "michael: i want to go to the guy who wants to go to the guy and going to get the best business school. \n",
            "\n",
            "michael: i want to go to the time. \n",
            "\n",
            "michael: i want to go to the guy who wants to go to the parking lot. \n",
            "\n",
            "michael: i want to go to the time. \n",
            "\n",
            "michael: i want to go to the time. \n",
            "\n",
            "dwight: i want to talk to you and then i was a good guy and going to be a good time. \n",
            "\n",
            "michael: i want to go to the time. \n",
            "\n",
            "dwight: i want to talk to you and then i was a good guy and good to the best dundies and go and we were to the parking lot. \n",
            "\n",
            "michael: i want to go to the time. \n",
            "\n",
            "dwight: i want to talk to you and then i was a good guy and good to the best dundie. \n",
            "\n",
            "michael: i want to go to the time. \n",
            "\n",
            "michael: i want to go to the time. \n",
            "\n",
            "michael: i want to go to the time. \n",
            "\n",
            "dwight: i want to go to the time. \n",
            "\n",
            "michael: i want to go to the time. \n",
            "\n",
            "dwight: i want to talk to you and then i was a good guy and going to be a little bit. \n",
            "\n",
            "dwight: i want to talk to you and then i was a good guy and good to the best dundies and go and we were the best business school. \n",
            "\n",
            "michael: i want to go to the time. \n",
            "\n",
            "dwight: i want to talk to you and then i was a good guy and going to be a good guy and good to the best dundies and go and we were to the parking lot. \n",
            "\n",
            "michael: i want to go to the time. \n",
            "\n",
            "dwight: i want to talk to you and then i was a good guy and going to get the fire guy. \n",
            "\n",
            "michael: i want to go to the time. \n",
            "\n",
            "michael: i want to go to the time. \n",
            "\n",
            "michael: i want to go to the time. \n",
            "\n",
            "dwight: i want to talk to you and then i was an alleade. \n",
            "\n",
            "michael: i want to go to the time. \n",
            "\n",
            "dwight: i want to talk to you and then i want to say that i was a good guy and good to the best dundies and go and we were to the parking lot. \n",
            "\n",
            "michael: i want to go to the guy who wants to go to the guy and going to get the fire guy. \n",
            "\n",
            "michael: i want to go to the time. \n",
            "\n",
            "dwight: i want to talk to you and then i was a good guy and good to the best dundie. \n",
            "\n",
            "michael: i want to go to the time. \n",
            "\n",
            "dwight: i want to talk to you and then i want to say that i was a good guy and good to the best dundies and go and we were to the parking lot. \n",
            "\n",
            "michael: i want to go to the parking lot. \n",
            "\n",
            "michael: i want to go to the time. \n",
            "\n",
            "dwight: i want to talk to you and then i want to say that i was a good guy and good to the best dundies and going to be a little bit. \n",
            "\n",
            "michael: i want to go to the time. \n",
            "\n",
            "michael: i want to go to the time. \n",
            "\n",
            "dwight: i want to go to the time. \n",
            "\n",
            "michael: i want to go to the guy who wants to go to the guy who wants to go to the time. \n",
            "\n",
            "michael: i want to go to the time. \n",
            "\n",
            "michael: i want to go to the time. \n",
            "\n",
            "dwight: i want to talk to you and then i was a good guy and going to be a good time. \n",
            "\n",
            "michael: i want to go to the time. \n",
            "\n",
            "dwight: i want to talk to you and then i was a good guy and i want to go to the time. \n",
            "\n",
            "michael: i want to go to the time. \n",
            "\n",
            "michael: i want to go to the time. \n",
            "\n",
            "dwight: i want to take the same time and going to get the best business school. \n",
            "\n",
            "michael: i want to go to the time. \n",
            "\n",
            "michael: i want to go to the time. \n",
            "\n",
            "dwight: i want to take the sale that i was a good guy and good to the best dundies and go and we were to the parking lot. \n",
            "\n",
            "michael: i want to go to the guy who wants to go to the guy and going to get the bathroom. \n",
            "\n",
            "michael: i want to go to the time. \n",
            "\n",
            "michael: i want to go to the time. \n",
            "\n",
            "dwight: i want to talk to you and then i was a good guy and going to be a good time. \n",
            "\n",
            "michael: i want to go to the guy who wants to go to the time. \n",
            "\n",
            "michael: i want to go to the time. \n",
            "\n",
            "dwight: i want to go to the time. \n",
            "\n",
            "michael: i want to go to the time. \n",
            "\n",
            "michael: i want to go to the guy who wants to go to the time. \n",
            "\n",
            "michael: i want to go to the time. \n",
            "\n",
            "michael: i want to go to the guy who wants to go to the parking lot. \n",
            "\n",
            "michael: i want to go to the time. \n",
            "\n",
            "michael: i want to go to the time. \n",
            "\n",
            "dwight: i want to talk to you and then i was a good guy and going to be a good guy and good to the best dundies and go and we were to the parking lot. \n",
            "\n",
            "michael: i want to go to the time. \n",
            "\n",
            "dwight: i want to talk to you and then i was a good guy and going to be a good time. \n",
            "\n",
            "michael: i want to go to the time. \n",
            "\n",
            "dwight: i want to talk to you and i want to go to the time. \n",
            "\n",
            "michael: i want to go to the time. \n",
            "\n",
            "d\n",
            "CPU times: user 6min 9s, sys: 13.3 s, total: 6min 22s\n",
            "Wall time: 6min 24s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "TEXT_LENGTH  = 5000\n",
        "LOOPBREAKER = 3\n",
        "#Generating new scripts\n",
        "\n",
        "\n",
        "x = np.random.randint(0, len(X_train)-1)\n",
        "pattern = X_train[x]\n",
        "outp = []\n",
        "for t in range(TEXT_LENGTH):\n",
        "    if t % 500 == 0:\n",
        "        print(\"%\"+str((t/TEXT_LENGTH)*100)+\" done\")\n",
        "        \n",
        "    x = np.reshape(pattern, (1, len(pattern)))\n",
        "    pred = model.predict(x, verbose=0)\n",
        "    result = np.argmax(pred)\n",
        "    outp.append(result)\n",
        "    pattern = np.append(pattern,result)\n",
        "    pattern = pattern[1:len(pattern)]\n",
        "    ####loopbreaker####\n",
        "    if t % LOOPBREAKER == 0:\n",
        "        pattern[np.random.randint(0, len(pattern)-10)] = np.random.randint(0, len(charindex)-1)\n",
        "\n",
        "#Let's see the results\n",
        "outp = [charindex[x] for x in outp]\n",
        "outp = ''.join(outp)\n",
        "\n",
        "print(outp)\n",
        "\n",
        "\n",
        "\n",
        "#Save the text output\n",
        "# f =  open(\"output_text_sample.txt\",\"w\")\n",
        "# f.write(outp)\n",
        "# f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkUlZFXLSfk2"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Office_Generation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNyza2MHGk/1a/kqAn2M7eI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
